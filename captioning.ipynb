{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Captioning"
      ],
      "metadata": {
        "id": "V8SpNQwI5Rzw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aMWTRIHfGyY"
      },
      "outputs": [],
      "source": [
        "!pip install deep-translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBwZ7ATsoSbD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "from deep_translator import GoogleTranslator\n",
        "import time\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ga4J81GreJ0k"
      },
      "outputs": [],
      "source": [
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "def generate_caption(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    output_ids = model.generate(**inputs)\n",
        "    caption = processor.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "def translate_caption(caption, target_lang='de'):\n",
        "    translator = GoogleTranslator(source='en', target=target_lang)\n",
        "    translated_caption = translator.translate(caption)\n",
        "    return translated_caption\n",
        "\n",
        "main_dir = '/content/drive/MyDrive/Projekt_Mobilisierung/Data/LINKE'\n",
        "output_dir = '/content/drive/MyDrive/Projekt_Mobilisierung/Data/LINKE'\n",
        "progress_file = os.path.join(output_dir, 'processed_images.txt')\n",
        "\n",
        "image_paths = [\n",
        "    os.path.join(root, file)\n",
        "    for root, _, files in os.walk(main_dir)\n",
        "    for file in files\n",
        "    if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')) and not file.lower().endswith('.zip')\n",
        "]\n",
        "\n",
        "if os.path.exists(progress_file):\n",
        "    with open(progress_file, 'r') as f:\n",
        "        processed_images = set(f.read().splitlines())\n",
        "else:\n",
        "    processed_images = set()\n",
        "\n",
        "image_paths_to_process = [path for path in image_paths if path not in processed_images]\n",
        "\n",
        "sample_size = 10\n",
        "sample_paths = image_paths_to_process[:sample_size]\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "sample_data = [\n",
        "    {\n",
        "        'image_path': path,\n",
        "        'caption': translate_caption(generate_caption(path))\n",
        "    }\n",
        "    for path in sample_paths\n",
        "]\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "avg_time_per_image = (end_time - start_time) / sample_size\n",
        "total_images = len(image_paths_to_process)\n",
        "estimated_total_time = total_images * avg_time_per_image\n",
        "\n",
        "print(f\"Durchschnittliche Zeit pro Bild: {avg_time_per_image:.2f} Sekunden\")\n",
        "print(f\"Geschätzte Gesamtzeit für alle Bilder: {estimated_total_time:.2f} Sekunden ({estimated_total_time / 60:.2f} Minuten)\")\n",
        "\n",
        "existing_batches = [\n",
        "    int(re.search(r'batch_(\\d+).csv', file).group(1))\n",
        "    for file in os.listdir(output_dir)\n",
        "    if re.search(r'batch_(\\d+).csv', file)\n",
        "]\n",
        "\n",
        "if existing_batches:\n",
        "    next_batch_number = max(existing_batches) + 1\n",
        "else:\n",
        "    next_batch_number = 1\n",
        "\n",
        "batch_size = 50\n",
        "data = []\n",
        "\n",
        "for i, image_path in enumerate(image_paths_to_process):\n",
        "    caption = generate_caption(image_path)\n",
        "    translated_caption = translate_caption(caption)\n",
        "    data.append({'image_path': image_path, 'caption': translated_caption})\n",
        "\n",
        "    if (i + 1) % batch_size == 0 or (i + 1) == total_images:\n",
        "        df = pd.DataFrame(data)\n",
        "        df.to_csv(os.path.join(output_dir, f'all_images_with_captions_batch_{next_batch_number}.csv'), index=False)\n",
        "\n",
        "        with open(progress_file, 'a') as f:\n",
        "            for item in data:\n",
        "                f.write(f\"{item['image_path']}\\n\")\n",
        "\n",
        "        data = []\n",
        "        next_batch_number += 1\n",
        "\n",
        "if data:\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(os.path.join(output_dir, f'all_images_with_captions_batch_{next_batch_number}.csv'), index=False)\n",
        "    with open(progress_file, 'a') as f:\n",
        "        for item in data:\n",
        "            f.write(f\"{item['image_path']}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaVrPZce0u5t"
      },
      "outputs": [],
      "source": [
        "input_dir = '/content/drive/MyDrive/Projekt_Mobilisierung/Data/LINKE'\n",
        "output_file = os.path.join(input_dir, 'all_images_with_captions_combined.csv')\n",
        "additional_file = os.path.join(input_dir, 'all_images_with_captions_combined.csv')\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.startswith('all_images_with_captions_batch_') and filename.endswith('.csv'):\n",
        "        file_path = os.path.join(input_dir, filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "        dfs.append(df)\n",
        "\n",
        "if os.path.exists(additional_file):\n",
        "    df_additional = pd.read_csv(additional_file)\n",
        "    dfs.append(df_additional)\n",
        "\n",
        "combined_df = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
        "\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Alle Dateien wurden zusammengeführt und in {output_file} gespeichert.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6XsRoi127eg",
        "outputId": "77ea2dc2-22e9-4921-a08a-677ee688ee36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alle Bildpfade aus der TXT-Datei sind in der CSV-Datei vorhanden.\n"
          ]
        }
      ],
      "source": [
        "csv_file = '/content/drive/MyDrive/Projekt_Mobilisierung/Data/LINKE/all_images_with_captions_combined.csv'\n",
        "txt_file = '/content/drive/MyDrive/Projekt_Mobilisierung/Data/LINKE/processed_images.txt'\n",
        "\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "csv_image_paths = set(df['image_path'])\n",
        "\n",
        "with open(txt_file, 'r') as f:\n",
        "    txt_image_paths = set(f.read().splitlines())\n",
        "\n",
        "missing_paths = txt_image_paths - csv_image_paths\n",
        "\n",
        "if missing_paths:\n",
        "    print(f\"Die folgenden {len(missing_paths)} Bildpfade aus der TXT-Datei sind nicht in der CSV-Datei vorhanden:\")\n",
        "    for path in missing_paths:\n",
        "        print(path)\n",
        "    txt_image_paths = txt_image_paths - missing_paths\n",
        "    with open(txt_file, 'w') as f:\n",
        "        for path in sorted(txt_image_paths):\n",
        "            f.write(f\"{path}\\n\")\n",
        "    print(f\"{len(missing_paths)} Pfade wurden aus der TXT-Datei entfernt.\")\n",
        "else:\n",
        "    print(\"Alle Bildpfade aus der TXT-Datei sind in der CSV-Datei vorhanden.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NFEb5Xp0TVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb29fbe1-4fa0-4fc2-f740-1711f4d84894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alle Dateien wurden zusammengeführt und in /content/drive/MyDrive/Projekt_Mobilisierung/Data/all_images_with_captions_combined_final.csv gespeichert.\n"
          ]
        }
      ],
      "source": [
        "root_dir = '/content/drive/MyDrive/Projekt_Mobilisierung/Data'\n",
        "output_file = os.path.join(root_dir, 'all_images_with_captions_combined_final.csv')\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for subdir, _, files in os.walk(root_dir):\n",
        "    for file in files:\n",
        "        if file == 'all_images_with_captions_combined.csv':\n",
        "            file_path = os.path.join(subdir, file)\n",
        "            df = pd.read_csv(file_path)\n",
        "            dfs.append(df)\n",
        "\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Alle Dateien wurden zusammengeführt und in {output_file} gespeichert.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anfügen Captions an Trainingsdatensatz"
      ],
      "metadata": {
        "id": "1TrEXLyA5dRn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqKTGGgX16PJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ef51b8-85e1-4f52-d8e2-6d05ce6b56dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Die Dateien wurden zusammengeführt und in /content/drive/MyDrive/Projekt_Mobilisierung/Data/strat_caption.csv gespeichert.\n"
          ]
        }
      ],
      "source": [
        "root_dir = '/content/drive/MyDrive/Projekt_Mobilisierung/Data'\n",
        "all_images_file = os.path.join(root_dir, 'all_images_with_captions_combined_final.csv')\n",
        "all_accs_file = os.path.join(root_dir, 'anno_sample_strat_df.csv')\n",
        "output_file = os.path.join(root_dir, 'strat_caption.csv')\n",
        "\n",
        "all_images_df = pd.read_csv(all_images_file)\n",
        "all_accs_df = pd.read_csv(all_accs_file)\n",
        "\n",
        "all_images_df['image_id'] = all_images_df['image_path'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
        "\n",
        "combined_df = pd.merge(all_images_df, all_accs_df, left_on='image_id', right_on='id', how='inner')\n",
        "\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Die Dateien wurden zusammengeführt und in {output_file} gespeichert.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quellen:\n",
        "\n",
        "Achmann-Denkler, M. (2024). michaelachmann/social-media-lab: DOI Release (v0.0.12). Zenodo. https://doi.org/10.5281/zenodo.10618621\n",
        "\n",
        "Achmann-Denkler, M. (2024). “Visual Exploration.” January 15, 2024. https://doi.org/10.5281/zenodo.10039756."
      ],
      "metadata": {
        "id": "Mp9i9KYnq20A"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}